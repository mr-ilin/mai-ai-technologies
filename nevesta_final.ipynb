{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работу выполнили:\n",
    "\n",
    "Студенты группы 208М:  \n",
    "Филатова Лада   \n",
    "Ильин Илья  \n",
    "Ланин Олег  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание:\n",
    "1. Невеста ищет себе жениха (существует единственное вакантное место).\n",
    "2. Число претендентов - N.\n",
    "3. Невеста общается с претендентами в случайном порядке, с каждым не более одного раза.\n",
    "4. О каждом претенденте известно, лучше он или хуже любого из предыдущих.\n",
    "5. Пообщавшись с претендентом, невеста сравнивает его с предыдущими и либо отказывает, либо принимает его предложение. Если предложение принято, они женятся и процесс останавливается. Если невеста отказывает жениху, то вернуться к нему позже она не сможет.\n",
    "6. Невеста выигрывает, если она выберет самого лучшего претендента. Выбор даже второго по порядку сравнения — проигрыш.\n",
    "\n",
    "Задача:\n",
    "1. Разработать и обучить нейронную сеть, которая возьмет на себя роль невесты и будет решать принять предложение или отказать очередному жениху.\n",
    "2. Сравнить результат принятия решения обученной нейронной сети и оптимальным математическим алгоритмом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание окружения BrideChoiceEnv, которое моделирует процесс выбора жениха."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrideChoiceEnv(gym.Env):\n",
    "    def __init__(self, n_candidates):\n",
    "        super(BrideChoiceEnv, self).__init__()\n",
    "        \n",
    "        self.n_candidates = n_candidates  #число претендентов\n",
    "        self.candidates = np.arange(1, n_candidates + 1)  \n",
    "        self.random_order = np.random.permutation(self.candidates)  \n",
    "        self.best_candidate = np.max(self.candidates)  #лучший претендент \n",
    "        \n",
    "        self.current_candidate_idx = 0  \n",
    "        self.previous_best = -1  \n",
    "        self.chosen_candidate = None  \n",
    "        self.previous_candidates = []  \n",
    "        \n",
    "\n",
    "        #определение пространства действий (0 - отказать, 1 - принять)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        \n",
    "        #определение пространства наблюдений: нормированный номер шага и флаг, лучше ли кандидат предыдущего\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'norm_num':spaces.Box(0, 1, dtype=np.float32),\n",
    "            'is_better':spaces.Discrete(2)\n",
    "        })\n",
    "        \n",
    "    def reset(self, seed = None): #перезапуск \n",
    "        super().reset(seed = seed)\n",
    "        np.random.seed(seed)\n",
    "        self.random_order = np.random.permutation(self.candidates)  \n",
    "        self.current_candidate_idx = 0\n",
    "        self.previous_best = -1\n",
    "        self.chosen_candidate = None\n",
    "        self.previous_candidates = []\n",
    "        return self._get_observation(), {}\n",
    "    \n",
    "    def _get_observation(self): #смотрим на текущего кандидата\n",
    "        normalized_step = self.current_candidate_idx / (self.n_candidates) if self.n_candidates > 1 else 0\n",
    "        #лучше ли он по сравнению с предыдущим максимумом\n",
    "        if self.current_candidate_idx < self.n_candidates:\n",
    "            current_is_better = self.random_order[self.current_candidate_idx] >= self.previous_best\n",
    "        else:\n",
    "            current_is_better = 0\n",
    "        return {\"norm_num\":np.array([normalized_step], dtype=np.float32), \"is_better\": int(current_is_better)}\n",
    "    \n",
    "    \n",
    "    def step(self, action): #шаг, \n",
    "        current_candidate = self.random_order[self.current_candidate_idx]  #текущий\n",
    "        done = False\n",
    "        reward = 0\n",
    "        \n",
    "        if action == 1:  #принять кандидата\n",
    "            self.chosen_candidate = current_candidate\n",
    "            done = True\n",
    "            if self.chosen_candidate == self.best_candidate:  #если выбран лучший претендент - победа\n",
    "                reward = 1\n",
    "            else:\n",
    "                reward = -1 \n",
    "        else:  #отвергнуть, добавляем текущего в список отвергнутых\n",
    "            self.previous_candidates.append(current_candidate)\n",
    "            self.previous_best = max(self.previous_best, current_candidate)\n",
    "            self.current_candidate_idx += 1\n",
    "            \n",
    "            if self.current_candidate_idx == self.n_candidates:  #если все кандидаты просмотрены\n",
    "                done = True\n",
    "                if self.chosen_candidate == self.best_candidate:\n",
    "                    reward = 1  #победа, если выбран лучший\n",
    "                else:\n",
    "                    reward = -1  #проигрыш\n",
    "        \n",
    "        return self._get_observation(), reward, done, False, {}\n",
    "    \n",
    "    def render(self): #текущее состояние\n",
    "        if self.chosen_candidate is not None:\n",
    "            print(f\"Невеста выбрала претендента {self.chosen_candidate}.\")\n",
    "        else:\n",
    "            print(f\"Невеста продолжает искать... Претендент №{self.random_order[self.current_candidate_idx]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Математическая оптимальная стратегия. Основывается на правиле 1/е (37%).  \n",
    "Просматриваем первые 37% кандидатов (1/е), и после этого выбираем первого лучшего, которого встретим.  \n",
    "Если текущий шаг больше или равен 1/е и кандидат лучше всех предыдущих — выбрать кандидата (return 1).  \n",
    "Во всех остальных случаях — отказать (return 0).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36633333333333334"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = BrideChoiceEnv(100)\n",
    "\n",
    "# Оптимальная стратегия\n",
    "def optimal_strategy(step, is_best):\n",
    "    if step >= (1/np.e) and is_best:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "episodes = 3000\n",
    "optimal_wins = 0\n",
    "\n",
    "for _ in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        cur = obs[\"norm_num\"]\n",
    "        is_best = obs[\"is_better\"]\n",
    "        action = optimal_strategy(cur, is_best)\n",
    "        obs, reward, done, _, _ = env.step(action)\n",
    "    if reward == 1:\n",
    "        optimal_wins += 1\n",
    "\n",
    "optimal_wins/episodes #вероятность успеха"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейронная сеть. Применяется алгоритм Proximal Policy Optimization (PPO) — метод обучения с подкреплением (RL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.12     |\n",
      "|    ep_rew_mean     | -0.98    |\n",
      "| time/              |          |\n",
      "|    fps             | 1059     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.44        |\n",
      "|    ep_rew_mean          | -0.98       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 784         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021128453 |\n",
      "|    clip_fraction        | 0.748       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.673      |\n",
      "|    explained_variance   | -0.00724    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.147      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0819     |\n",
      "|    value_loss           | 0.0915      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.41       |\n",
      "|    ep_rew_mean          | -0.98      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 728        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03394832 |\n",
      "|    clip_fraction        | 0.694      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.584     |\n",
      "|    explained_variance   | 0.00239    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.108     |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0878    |\n",
      "|    value_loss           | 0.0164     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.61       |\n",
      "|    ep_rew_mean          | -0.98      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 708        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04894719 |\n",
      "|    clip_fraction        | 0.507      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.438     |\n",
      "|    explained_variance   | 0.00119    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.064      |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0522    |\n",
      "|    value_loss           | 0.0324     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 17.1       |\n",
      "|    ep_rew_mean          | -0.96      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 700        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06318708 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.274     |\n",
      "|    explained_variance   | -0.00129   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0309     |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.023     |\n",
      "|    value_loss           | 0.0399     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.92       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 696         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009310535 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.121      |\n",
      "|    explained_variance   | 0.0104      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00623    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.0321      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 42.8         |\n",
      "|    ep_rew_mean          | -0.88        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 691          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017146153 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0651      |\n",
      "|    explained_variance   | -0.055       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00434     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    value_loss           | 0.0313       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 51.5         |\n",
      "|    ep_rew_mean          | -0.84        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008954804 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0469      |\n",
      "|    explained_variance   | 0.0519       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00205      |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    value_loss           | 0.0354       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.6         |\n",
      "|    ep_rew_mean          | -0.72        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015118367 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0364      |\n",
      "|    explained_variance   | 0.0754       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00207      |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    value_loss           | 0.0588       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 66.2         |\n",
      "|    ep_rew_mean          | -0.58        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008719908 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0288      |\n",
      "|    explained_variance   | 0.013        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0692       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    value_loss           | 0.0972       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 70.4          |\n",
      "|    ep_rew_mean          | -0.52         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 680           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 33            |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051693444 |\n",
      "|    clip_fraction        | 0.00381       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0231       |\n",
      "|    explained_variance   | 0.0171        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0558        |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.00184      |\n",
      "|    value_loss           | 0.0959        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 72.5          |\n",
      "|    ep_rew_mean          | -0.38         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 677           |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 36            |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032308378 |\n",
      "|    clip_fraction        | 0.0019        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0174       |\n",
      "|    explained_variance   | 0.0668        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0321        |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -7.57e-05     |\n",
      "|    value_loss           | 0.0882        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 69.5          |\n",
      "|    ep_rew_mean          | -0.36         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 676           |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 39            |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034629053 |\n",
      "|    clip_fraction        | 0.00332       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0142       |\n",
      "|    explained_variance   | 0.127         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0387        |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.00139      |\n",
      "|    value_loss           | 0.0874        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 73.9          |\n",
      "|    ep_rew_mean          | -0.36         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 675           |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 42            |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033240393 |\n",
      "|    clip_fraction        | 0.0042        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0127       |\n",
      "|    explained_variance   | 0.0349        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0711        |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    value_loss           | 0.118         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 75.3          |\n",
      "|    ep_rew_mean          | -0.3          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 674           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 45            |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013185358 |\n",
      "|    clip_fraction        | 0.00142       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0101       |\n",
      "|    explained_variance   | 0.0765        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0498        |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -5.23e-05     |\n",
      "|    value_loss           | 0.0892        |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.6       |\n",
      "|    ep_rew_mean          | -0.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 674        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 48         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00026635 |\n",
      "|    clip_fraction        | 0.00327    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0106    |\n",
      "|    explained_variance   | 0.258      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0392     |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.000785  |\n",
      "|    value_loss           | 0.0763     |\n",
      "----------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 81.6           |\n",
      "|    ep_rew_mean          | -0.38          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 674            |\n",
      "|    iterations           | 17             |\n",
      "|    time_elapsed         | 51             |\n",
      "|    total_timesteps      | 34816          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000120288794 |\n",
      "|    clip_fraction        | 0.000732       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00934       |\n",
      "|    explained_variance   | 0.274          |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 0.0409         |\n",
      "|    n_updates            | 160            |\n",
      "|    policy_gradient_loss | -0.00023       |\n",
      "|    value_loss           | 0.0799         |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 82            |\n",
      "|    ep_rew_mean          | -0.36         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 673           |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 54            |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064722105 |\n",
      "|    clip_fraction        | 0.00566       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.011        |\n",
      "|    explained_variance   | 0.435         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0286        |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.0025       |\n",
      "|    value_loss           | 0.0629        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 83.3          |\n",
      "|    ep_rew_mean          | -0.34         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 673           |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 57            |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041395315 |\n",
      "|    clip_fraction        | 0.0041        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0105       |\n",
      "|    explained_variance   | 0.373         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0329        |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.000668     |\n",
      "|    value_loss           | 0.0793        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 83.5          |\n",
      "|    ep_rew_mean          | -0.28         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 673           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 60            |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018219285 |\n",
      "|    clip_fraction        | 0.00181       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00685      |\n",
      "|    explained_variance   | 0.229         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0387        |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -9.64e-05     |\n",
      "|    value_loss           | 0.0955        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 79.1          |\n",
      "|    ep_rew_mean          | -0.32         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 673           |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 63            |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061514927 |\n",
      "|    clip_fraction        | 0.00479       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00961      |\n",
      "|    explained_variance   | 0.12          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0502        |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.000886     |\n",
      "|    value_loss           | 0.103         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 75.1          |\n",
      "|    ep_rew_mean          | -0.28         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 673           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 66            |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027668005 |\n",
      "|    clip_fraction        | 0.0019        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0111       |\n",
      "|    explained_variance   | 0.198         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0411        |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -9.66e-05     |\n",
      "|    value_loss           | 0.0992        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 69.7          |\n",
      "|    ep_rew_mean          | -0.22         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 673           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 69            |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050186866 |\n",
      "|    clip_fraction        | 0.00518       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00865      |\n",
      "|    explained_variance   | 0.223         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0726        |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.00121      |\n",
      "|    value_loss           | 0.103         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.7         |\n",
      "|    ep_rew_mean          | -0.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 672          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.672697e-05 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00897     |\n",
      "|    explained_variance   | 0.15         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0647       |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000302    |\n",
      "|    value_loss           | 0.129        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 73.2          |\n",
      "|    ep_rew_mean          | -0.24         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 673           |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 76            |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6672096e-05 |\n",
      "|    clip_fraction        | 0.000586      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.01         |\n",
      "|    explained_variance   | 0.312         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0244        |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | 0.000153      |\n",
      "|    value_loss           | 0.0847        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 76.6          |\n",
      "|    ep_rew_mean          | -0.3          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 673           |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 79            |\n",
      "|    total_timesteps      | 53248         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012972747 |\n",
      "|    clip_fraction        | 0.00161       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00815      |\n",
      "|    explained_variance   | 0.47          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0495        |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | -9.44e-05     |\n",
      "|    value_loss           | 0.0619        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 81.4          |\n",
      "|    ep_rew_mean          | -0.46         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 673           |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 82            |\n",
      "|    total_timesteps      | 55296         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011824966 |\n",
      "|    clip_fraction        | 0.000977      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00728      |\n",
      "|    explained_variance   | 0.441         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0624        |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | -0.000197     |\n",
      "|    value_loss           | 0.0738        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 85.5          |\n",
      "|    ep_rew_mean          | -0.42         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 672           |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 85            |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4332909e-05 |\n",
      "|    clip_fraction        | 0.000586      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00628      |\n",
      "|    explained_variance   | 0.506         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0113        |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -5.9e-05      |\n",
      "|    value_loss           | 0.0629        |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 82           |\n",
      "|    ep_rew_mean          | -0.26        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 671          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003595832 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00613     |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0196       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00038     |\n",
      "|    value_loss           | 0.0875       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 79.2          |\n",
      "|    ep_rew_mean          | -0.22         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 670           |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 91            |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014669381 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0075       |\n",
      "|    explained_variance   | 0.233         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0491        |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -0.000278     |\n",
      "|    value_loss           | 0.111         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.7        |\n",
      "|    ep_rew_mean          | -0.18       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 669         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010980221 |\n",
      "|    clip_fraction        | 0.0214      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0305     |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0177      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 0.0932      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.4        |\n",
      "|    ep_rew_mean          | -0.28       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002021902 |\n",
      "|    clip_fraction        | 0.00854     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0231     |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0425      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.000752   |\n",
      "|    value_loss           | 0.0833      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.1        |\n",
      "|    ep_rew_mean          | -0.36       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009639395 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0088     |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0248      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    value_loss           | 0.0905      |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 75.1          |\n",
      "|    ep_rew_mean          | -0.46         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 667           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 104           |\n",
      "|    total_timesteps      | 69632         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074785034 |\n",
      "|    clip_fraction        | 0.00313       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00757      |\n",
      "|    explained_variance   | 0.292         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0695        |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -0.000306     |\n",
      "|    value_loss           | 0.1           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77           |\n",
      "|    ep_rew_mean          | -0.44        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 668          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015237527 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00468     |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0233       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000406    |\n",
      "|    value_loss           | 0.0577       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x183fda26f30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = BrideChoiceEnv(100)\n",
    "\n",
    "model = PPO(\"MultiInputPolicy\", env, verbose=1)\n",
    "\n",
    "training_steps = 70_000  #шаги обучения\n",
    "model.learn(total_timesteps=training_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На каждом шаге модель получает текущее состояние (obs), включающее:  \n",
    "norm_num: нормализованный номер шага  \n",
    "is_better: флаг, лучше ли текущий кандидат предыдущих  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.353"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = BrideChoiceEnv(100)\n",
    "\n",
    "episodes = 1000\n",
    "model_wins = 0\n",
    "\n",
    "for _ in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs) #предсказывает выбрать кандидата или продолжить поиск\n",
    "        obs, reward, done, _, _ = env.step(action)\n",
    "        \n",
    "    if reward == 1:\n",
    "        model_wins += 1\n",
    "\n",
    "model_wins/episodes #вероятность успеха модели"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
