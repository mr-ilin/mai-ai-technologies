# Выводы:
- 1D-CNN показал более стабильные результаты с хорошей производительностью как на обучающих данных, так и на валидационных. Этот тип сети, вероятно, лучше подходит для нашей задачи в виду размера текста и того факта, что, сверточные слои хорошо работают с локальными зависимостями и могут быстрее обучаться.
- LSTM и GRU требуют большего времени на обучение и могут показывать хорошие результаты в задачах, требующих последовательной обработки данных (например, текста), но их обучение гораздо более затратное по времени и ресурсам, особенно если данных очень много. В отличие от 1D-CNN, RNN модели начали с гораздо более низкой точности (0.25) и значительных потерь, но улучшили точность на валидации (приблизительно 0.89-0.90 к 20-му эпоху)
